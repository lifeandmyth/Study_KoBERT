{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KoBERT finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "id": "-sx87sgK7_pz",
    "outputId": "9f1c67bf-7c67-45d7-88b7-4bbc7384a29b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://****@github.com/lifeandmyth/study_KoBERT.git@master\n",
      "  Cloning https://****@github.com/lifeandmyth/study_KoBERT.git (to revision master) to c:\\users\\hi\\appdata\\local\\temp\\pip-req-build-x8whkm49\n",
      "  Resolved https://****@github.com/lifeandmyth/study_KoBERT.git to commit 551a88688478496e49d3c72d42e3a736a4cb1504\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting boto3<=1.15.18 (from kobert==0.2.3)\n",
      "  Using cached boto3-1.15.18-py2.py3-none-any.whl (129 kB)\n",
      "Collecting gluonnlp<=0.10.0,>=0.6.0 (from kobert==0.2.3)\n",
      "  Using cached gluonnlp-0.10.0.tar.gz (344 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting mxnet<=1.7.0.post2,>=1.4.0 (from kobert==0.2.3)\n",
      "  Using cached mxnet-1.7.0.post2-py2.py3-none-win_amd64.whl (33.1 MB)\n",
      "Requirement already satisfied: onnxruntime<=1.16.0,==1.16.0 in c:\\users\\hi\\anaconda3\\envs\\kobert_c_venv\\lib\\site-packages (from kobert==0.2.3) (1.16.0)\n",
      "Collecting sentencepiece<=0.1.96,>=0.1.6 (from kobert==0.2.3)\n",
      "  Using cached sentencepiece-0.1.96.tar.gz (508 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: torch<=2.0.2,>=1.7.0 in c:\\users\\hi\\anaconda3\\envs\\kobert_c_venv\\lib\\site-packages (from kobert==0.2.3) (2.0.1+cu117)\n",
      "Collecting transformers<=4.8.1,>=4.8.1 (from kobert==0.2.3)\n",
      "  Downloading transformers-4.8.1-py3-none-any.whl (2.5 MB)\n",
      "     ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.0/2.5 MB 653.6 kB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 0.4/2.5 MB 3.3 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 0.9/2.5 MB 5.4 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 1.4/2.5 MB 6.7 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 1.9/2.5 MB 7.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 2.4/2.5 MB 8.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.5/2.5 MB 7.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\hi\\anaconda3\\envs\\kobert_c_venv\\lib\\site-packages (from onnxruntime<=1.16.0,==1.16.0->kobert==0.2.3) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\hi\\anaconda3\\envs\\kobert_c_venv\\lib\\site-packages (from onnxruntime<=1.16.0,==1.16.0->kobert==0.2.3) (23.5.26)\n",
      "Requirement already satisfied: numpy>=1.24.2 in c:\\users\\hi\\anaconda3\\envs\\kobert_c_venv\\lib\\site-packages (from onnxruntime<=1.16.0,==1.16.0->kobert==0.2.3) (1.26.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hi\\anaconda3\\envs\\kobert_c_venv\\lib\\site-packages (from onnxruntime<=1.16.0,==1.16.0->kobert==0.2.3) (23.1)\n",
      "Requirement already satisfied: protobuf in c:\\users\\hi\\anaconda3\\envs\\kobert_c_venv\\lib\\site-packages (from onnxruntime<=1.16.0,==1.16.0->kobert==0.2.3) (4.24.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\hi\\anaconda3\\envs\\kobert_c_venv\\lib\\site-packages (from onnxruntime<=1.16.0,==1.16.0->kobert==0.2.3) (1.12)\n",
      "Collecting botocore<1.19.0,>=1.18.18 (from boto3<=1.15.18->kobert==0.2.3)\n",
      "  Downloading botocore-1.18.18-py2.py3-none-any.whl (6.7 MB)\n",
      "     ---------------------------------------- 0.0/6.7 MB ? eta -:--:--\n",
      "     --- ------------------------------------ 0.6/6.7 MB 11.8 MB/s eta 0:00:01\n",
      "     ------ --------------------------------- 1.0/6.7 MB 13.3 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 1.6/6.7 MB 12.5 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 2.1/6.7 MB 12.2 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 2.6/6.7 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 3.1/6.7 MB 11.7 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 3.6/6.7 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 4.1/6.7 MB 11.5 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 4.7/6.7 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 5.2/6.7 MB 11.9 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 5.7/6.7 MB 11.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 6.2/6.7 MB 11.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  6.7/6.7 MB 11.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  6.7/6.7 MB 11.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 6.7/6.7 MB 10.7 MB/s eta 0:00:00\n",
      "Collecting jmespath<1.0.0,>=0.7.1 (from boto3<=1.15.18->kobert==0.2.3)\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0 (from boto3<=1.15.18->kobert==0.2.3)\n",
      "  Downloading s3transfer-0.3.7-py2.py3-none-any.whl (73 kB)\n",
      "     ---------------------------------------- 0.0/73.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 73.4/73.4 kB ? eta 0:00:00\n",
      "Collecting cython (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3)\n",
      "  Obtaining dependency information for cython from https://files.pythonhosted.org/packages/ea/8f/216de5d7bede3e26a7131b427a8aadade032f03f9c8ee88792def02e2cf4/Cython-3.0.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached Cython-3.0.2-cp311-cp311-win_amd64.whl.metadata (3.2 kB)\n",
      "INFO: pip is looking at multiple versions of mxnet to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting mxnet<=1.7.0.post2,>=1.4.0 (from kobert==0.2.3)\n",
      "  Downloading mxnet-1.7.0.post1-py2.py3-none-win_amd64.whl (33.0 MB)\n",
      "     ---------------------------------------- 0.0/33.0 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.5/33.0 MB 14.9 MB/s eta 0:00:03\n",
      "     - -------------------------------------- 1.0/33.0 MB 12.2 MB/s eta 0:00:03\n",
      "     - -------------------------------------- 1.5/33.0 MB 11.6 MB/s eta 0:00:03\n",
      "     -- ------------------------------------- 2.0/33.0 MB 11.4 MB/s eta 0:00:03\n",
      "     -- ------------------------------------- 2.4/33.0 MB 10.9 MB/s eta 0:00:03\n",
      "     --- ------------------------------------ 2.7/33.0 MB 10.3 MB/s eta 0:00:03\n",
      "     --- ------------------------------------ 3.3/33.0 MB 10.4 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 3.8/33.0 MB 10.5 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 4.3/33.0 MB 10.9 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 4.8/33.0 MB 10.9 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 5.3/33.0 MB 10.9 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 5.8/33.0 MB 10.9 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 6.3/33.0 MB 10.9 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 6.8/33.0 MB 10.9 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 7.3/33.0 MB 10.9 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 7.8/33.0 MB 10.9 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 8.3/33.0 MB 10.9 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 8.8/33.0 MB 11.0 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 9.3/33.0 MB 11.0 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 9.8/33.0 MB 11.0 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 10.3/33.0 MB 10.9 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 10.9/33.0 MB 11.1 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 11.4/33.0 MB 11.1 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 11.9/33.0 MB 10.9 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 12.4/33.0 MB 11.1 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 12.9/33.0 MB 11.3 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 13.4/33.0 MB 11.3 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 13.9/33.0 MB 11.3 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 14.4/33.0 MB 11.3 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 14.9/33.0 MB 11.3 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 15.4/33.0 MB 11.1 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 15.9/33.0 MB 11.1 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 16.4/33.0 MB 11.1 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 16.9/33.0 MB 11.1 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 17.4/33.0 MB 11.1 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 17.9/33.0 MB 11.3 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 18.5/33.0 MB 11.3 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 19.0/33.0 MB 11.3 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 19.5/33.0 MB 11.3 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 20.0/33.0 MB 11.3 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 20.5/33.0 MB 11.3 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 21.0/33.0 MB 11.1 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 21.5/33.0 MB 11.1 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 22.0/33.0 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 22.4/33.0 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 22.9/33.0 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 23.1/33.0 MB 10.7 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 23.6/33.0 MB 10.7 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 24.1/33.0 MB 10.7 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 24.6/33.0 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 25.1/33.0 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 25.7/33.0 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 26.2/33.0 MB 10.9 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 26.7/33.0 MB 10.9 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 27.2/33.0 MB 10.9 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 27.7/33.0 MB 10.9 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 28.3/33.0 MB 10.9 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 28.8/33.0 MB 10.9 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 29.3/33.0 MB 10.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 29.8/33.0 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 30.3/33.0 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 30.8/33.0 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 31.3/33.0 MB 10.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 31.9/33.0 MB 11.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  32.4/33.0 MB 11.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  32.8/33.0 MB 11.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  33.0/33.0 MB 11.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  33.0/33.0 MB 11.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  33.0/33.0 MB 11.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 33.0/33.0 MB 9.6 MB/s eta 0:00:00\n",
      "  Downloading mxnet-1.6.0-py2.py3-none-win_amd64.whl (26.9 MB)\n",
      "     ---------------------------------------- 0.0/26.9 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.5/26.9 MB 14.9 MB/s eta 0:00:02\n",
      "     - -------------------------------------- 1.0/26.9 MB 12.5 MB/s eta 0:00:03\n",
      "     -- ------------------------------------- 1.5/26.9 MB 11.9 MB/s eta 0:00:03\n",
      "     -- ------------------------------------- 2.0/26.9 MB 11.6 MB/s eta 0:00:03\n",
      "     --- ------------------------------------ 2.5/26.9 MB 11.5 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 3.1/26.9 MB 11.5 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 3.6/26.9 MB 12.0 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 4.1/26.9 MB 11.8 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 4.6/26.9 MB 11.8 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 5.1/26.9 MB 11.7 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 5.7/26.9 MB 11.7 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 6.2/26.9 MB 11.6 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 6.7/26.9 MB 11.6 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 7.2/26.9 MB 11.5 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 7.7/26.9 MB 11.4 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 8.2/26.9 MB 11.4 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 8.7/26.9 MB 11.6 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 9.2/26.9 MB 11.5 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 9.7/26.9 MB 11.5 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 10.2/26.9 MB 11.4 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 10.7/26.9 MB 11.3 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 11.2/26.9 MB 11.3 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 11.7/26.9 MB 11.3 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 12.2/26.9 MB 11.1 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 12.7/26.9 MB 11.1 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 13.2/26.9 MB 11.1 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 13.7/26.9 MB 11.3 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 14.2/26.9 MB 11.3 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 14.7/26.9 MB 11.1 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 15.2/26.9 MB 11.1 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 15.7/26.9 MB 11.1 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 16.2/26.9 MB 11.1 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 16.7/26.9 MB 11.1 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 17.2/26.9 MB 11.1 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 17.7/26.9 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 18.2/26.9 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 18.7/26.9 MB 11.1 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 19.2/26.9 MB 11.1 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 19.8/26.9 MB 11.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 20.3/26.9 MB 11.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 20.8/26.9 MB 11.1 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 21.3/26.9 MB 11.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 21.8/26.9 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 22.3/26.9 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 22.8/26.9 MB 11.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 23.3/26.9 MB 11.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 23.8/26.9 MB 11.3 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 24.4/26.9 MB 11.3 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 24.8/26.9 MB 11.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 25.3/26.9 MB 11.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 25.8/26.9 MB 11.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  26.3/26.9 MB 11.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  26.8/26.9 MB 11.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  26.8/26.9 MB 11.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  26.8/26.9 MB 11.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 26.9/26.9 MB 9.9 MB/s eta 0:00:00\n",
      "  Downloading mxnet-1.5.0-py2.py3-none-win_amd64.whl (23.5 MB)\n",
      "     ---------------------------------------- 0.0/23.5 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.4/23.5 MB 12.5 MB/s eta 0:00:02\n",
      "     - -------------------------------------- 0.9/23.5 MB 11.8 MB/s eta 0:00:02\n",
      "     -- ------------------------------------- 1.5/23.5 MB 11.7 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 2.0/23.5 MB 11.4 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 2.5/23.5 MB 11.2 MB/s eta 0:00:02\n",
      "     ----- ---------------------------------- 3.0/23.5 MB 11.2 MB/s eta 0:00:02\n",
      "     ----- ---------------------------------- 3.5/23.5 MB 11.7 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 4.0/23.5 MB 11.5 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 4.2/23.5 MB 11.1 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 4.3/23.5 MB 9.8 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 4.8/23.5 MB 9.9 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 5.4/23.5 MB 10.0 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 5.9/23.5 MB 10.1 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 6.4/23.5 MB 10.2 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 6.9/23.5 MB 10.2 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 7.4/23.5 MB 10.5 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 7.9/23.5 MB 10.5 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 8.4/23.5 MB 10.6 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 8.9/23.5 MB 10.6 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 9.5/23.5 MB 10.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 10.0/23.5 MB 10.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 10.5/23.5 MB 10.6 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 11.0/23.5 MB 10.6 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 11.5/23.5 MB 10.6 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 12.1/23.5 MB 10.7 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 12.6/23.5 MB 10.7 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 13.1/23.5 MB 10.7 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 13.6/23.5 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 14.1/23.5 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 14.7/23.5 MB 11.5 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 15.2/23.5 MB 11.5 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 15.7/23.5 MB 11.3 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 16.2/23.5 MB 11.3 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 16.7/23.5 MB 11.5 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 17.2/23.5 MB 11.5 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 17.7/23.5 MB 11.5 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 18.3/23.5 MB 11.5 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 18.8/23.5 MB 11.5 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 19.3/23.5 MB 11.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 19.8/23.5 MB 11.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 20.3/23.5 MB 11.5 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 20.9/23.5 MB 11.3 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 21.4/23.5 MB 11.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 21.9/23.5 MB 11.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 22.4/23.5 MB 11.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 22.9/23.5 MB 11.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  23.4/23.5 MB 11.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  23.5/23.5 MB 11.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  23.5/23.5 MB 11.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 23.5/23.5 MB 10.2 MB/s eta 0:00:00\n",
      "  Downloading mxnet-1.4.1-py2.py3-none-win_amd64.whl (21.9 MB)\n",
      "     ---------------------------------------- 0.0/21.9 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.4/21.9 MB 13.2 MB/s eta 0:00:02\n",
      "     - -------------------------------------- 0.9/21.9 MB 11.3 MB/s eta 0:00:02\n",
      "     -- ------------------------------------- 1.4/21.9 MB 10.7 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 1.8/21.9 MB 10.5 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 2.3/21.9 MB 10.5 MB/s eta 0:00:02\n",
      "     ----- ---------------------------------- 2.8/21.9 MB 10.4 MB/s eta 0:00:02\n",
      "     ----- ---------------------------------- 3.1/21.9 MB 10.6 MB/s eta 0:00:02\n",
      "     ----- ---------------------------------- 3.1/21.9 MB 10.6 MB/s eta 0:00:02\n",
      "     ----- ---------------------------------- 3.1/21.9 MB 10.6 MB/s eta 0:00:02\n",
      "     ----- ---------------------------------- 3.1/21.9 MB 10.6 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 3.6/21.9 MB 7.4 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 4.1/21.9 MB 7.7 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 4.6/21.9 MB 7.9 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 5.1/21.9 MB 8.1 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 5.5/21.9 MB 8.2 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 6.0/21.9 MB 8.3 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 6.5/21.9 MB 8.5 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 7.0/21.9 MB 8.6 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 7.5/21.9 MB 8.9 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 8.0/21.9 MB 9.0 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 8.5/21.9 MB 9.1 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 9.0/21.9 MB 9.1 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 9.5/21.9 MB 9.2 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 10.0/21.9 MB 9.2 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 10.5/21.9 MB 9.2 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 11.0/21.9 MB 9.2 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 11.5/21.9 MB 9.2 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 12.0/21.9 MB 9.5 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 12.5/21.9 MB 9.5 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 13.0/21.9 MB 9.5 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 13.6/21.9 MB 11.1 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 14.1/21.9 MB 11.1 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 14.6/21.9 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 15.1/21.9 MB 11.1 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 15.7/21.9 MB 11.1 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 16.2/21.9 MB 11.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 16.7/21.9 MB 11.3 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 17.2/21.9 MB 11.3 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 17.7/21.9 MB 11.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 18.3/21.9 MB 11.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 18.8/21.9 MB 11.5 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 19.3/21.9 MB 11.3 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 19.8/21.9 MB 11.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 20.4/21.9 MB 11.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 20.9/21.9 MB 11.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  21.4/21.9 MB 11.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  21.9/21.9 MB 11.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  21.9/21.9 MB 11.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  21.9/21.9 MB 11.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 21.9/21.9 MB 10.4 MB/s eta 0:00:00\n",
      "  Downloading mxnet-1.4.0.post0-py2.py3-none-win_amd64.whl (21.9 MB)\n",
      "     ---------------------------------------- 0.0/21.9 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.6/21.9 MB 17.5 MB/s eta 0:00:02\n",
      "     - -------------------------------------- 1.1/21.9 MB 13.5 MB/s eta 0:00:02\n",
      "     -- ------------------------------------- 1.6/21.9 MB 12.5 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 2.1/21.9 MB 12.1 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 2.6/21.9 MB 11.9 MB/s eta 0:00:02\n",
      "     ----- ---------------------------------- 3.1/21.9 MB 11.6 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 3.6/21.9 MB 11.5 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 4.1/21.9 MB 11.4 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 4.6/21.9 MB 11.8 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 5.2/21.9 MB 11.7 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 5.7/21.9 MB 11.6 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 6.2/21.9 MB 11.6 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 6.7/21.9 MB 11.6 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 7.2/21.9 MB 11.5 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 7.3/21.9 MB 11.4 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 7.3/21.9 MB 11.4 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 7.3/21.9 MB 11.4 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 7.5/21.9 MB 9.4 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 8.0/21.9 MB 9.4 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 8.4/21.9 MB 9.4 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 8.4/21.9 MB 9.0 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 8.9/21.9 MB 9.1 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 9.4/21.9 MB 9.1 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 9.9/21.9 MB 9.2 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 10.4/21.9 MB 9.1 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 10.9/21.9 MB 9.1 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 11.4/21.9 MB 9.2 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 11.9/21.9 MB 9.2 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 12.5/21.9 MB 9.2 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 13.0/21.9 MB 9.2 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 13.5/21.9 MB 9.2 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 14.0/21.9 MB 9.2 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 14.5/21.9 MB 9.2 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 15.0/21.9 MB 9.2 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 15.6/21.9 MB 9.4 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 16.1/21.9 MB 9.4 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 16.6/21.9 MB 9.2 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 17.1/21.9 MB 9.2 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 17.7/21.9 MB 10.7 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 18.1/21.9 MB 10.7 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 18.6/21.9 MB 11.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 19.1/21.9 MB 11.3 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 19.7/21.9 MB 11.3 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 20.2/21.9 MB 11.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 20.7/21.9 MB 11.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 21.2/21.9 MB 11.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  21.7/21.9 MB 11.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  21.9/21.9 MB 11.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  21.9/21.9 MB 11.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 21.9/21.9 MB 10.2 MB/s eta 0:00:00\n",
      "  Downloading mxnet-1.4.0-py2.py3-none-win_amd64.whl (21.9 MB)\n",
      "     ---------------------------------------- 0.0/21.9 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.5/21.9 MB 16.0 MB/s eta 0:00:02\n",
      "     - -------------------------------------- 1.0/21.9 MB 13.1 MB/s eta 0:00:02\n",
      "     -- ------------------------------------- 1.5/21.9 MB 12.3 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 2.1/21.9 MB 12.0 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 2.6/21.9 MB 11.7 MB/s eta 0:00:02\n",
      "     ----- ---------------------------------- 3.1/21.9 MB 11.6 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 3.6/21.9 MB 11.5 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 4.1/21.9 MB 11.4 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 4.6/21.9 MB 11.8 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 5.2/21.9 MB 11.7 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 5.7/21.9 MB 11.7 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 6.2/21.9 MB 11.6 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 6.7/21.9 MB 11.6 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 7.2/21.9 MB 11.5 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 7.7/21.9 MB 11.5 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 8.3/21.9 MB 11.5 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 8.7/21.9 MB 11.6 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 9.3/21.9 MB 11.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 9.8/21.9 MB 11.6 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 10.3/21.9 MB 11.5 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 10.8/21.9 MB 11.5 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 11.3/21.9 MB 11.5 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 11.9/21.9 MB 11.5 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 12.4/21.9 MB 11.5 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 12.9/21.9 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 13.4/21.9 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 13.9/21.9 MB 11.5 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 14.5/21.9 MB 11.5 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 15.0/21.9 MB 11.5 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 15.5/21.9 MB 11.5 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 16.0/21.9 MB 11.5 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 16.5/21.9 MB 11.5 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 17.1/21.9 MB 11.7 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 17.6/21.9 MB 11.7 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 18.1/21.9 MB 11.7 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 18.7/21.9 MB 11.7 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 19.2/21.9 MB 11.5 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 19.7/21.9 MB 11.5 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 20.2/21.9 MB 11.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 20.7/21.9 MB 11.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 21.2/21.9 MB 11.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  21.7/21.9 MB 11.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  21.9/21.9 MB 11.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  21.9/21.9 MB 11.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 21.9/21.9 MB 10.4 MB/s eta 0:00:00\n",
      "Collecting gluonnlp<=0.10.0,>=0.6.0 (from kobert==0.2.3)\n",
      "  Downloading gluonnlp-0.9.2.tar.gz (252 kB)\n",
      "     ---------------------------------------- 0.0/252.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 252.7/252.7 kB 15.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "INFO: pip is still looking at multiple versions of mxnet to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading gluonnlp-0.9.1.tar.gz (252 kB)\n",
      "     ---------------------------------------- 0.0/252.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 252.8/252.8 kB 7.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading gluonnlp-0.9.0.post0.tar.gz (252 kB)\n",
      "     ---------------------------------------- 0.0/252.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 252.8/252.8 kB 15.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading gluonnlp-0.8.3.tar.gz (236 kB)\n",
      "     ---------------------------------------- 0.0/236.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 236.3/236.3 kB 14.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading gluonnlp-0.8.2.tar.gz (237 kB)\n",
      "     ---------------------------------------- 0.0/237.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 237.5/237.5 kB 15.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading gluonnlp-0.8.1.tar.gz (236 kB)\n",
      "     ---------------------------------------- 0.0/236.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 236.4/236.4 kB 7.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading gluonnlp-0.8.0.tar.gz (235 kB)\n",
      "     ---------------------------------------- 0.0/235.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 235.5/235.5 kB 14.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading gluonnlp-0.7.1.tar.gz (233 kB)\n",
      "     ---------------------------------------- 0.0/233.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 233.4/233.4 kB 7.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading gluonnlp-0.7.0.tar.gz (233 kB)\n",
      "     ---------------------------------------- 0.0/233.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 233.5/233.5 kB 7.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading gluonnlp-0.6.0.tar.gz (209 kB)\n",
      "     ---------------------------------------- 0.0/209.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 209.5/209.5 kB 13.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting onnxruntime<=1.16.0,==1.16.0 (from kobert==0.2.3)\n",
      "  Obtaining dependency information for onnxruntime<=1.16.0,==1.16.0 from https://files.pythonhosted.org/packages/0c/14/9966e648a48f9bfee456002700cde4ca41f1e04ebaea842ccf663b6e7db2/onnxruntime-1.16.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached onnxruntime-1.16.0-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "\n",
      "The conflict is caused by:\n",
      "    onnxruntime 1.16.0 depends on numpy>=1.24.2\n",
      "    gluonnlp 0.6.0 depends on numpy\n",
      "    mxnet 1.7.0.post2 depends on numpy<1.17.0 and >=1.8.2\n",
      "    onnxruntime 1.16.0 depends on numpy>=1.24.2\n",
      "    gluonnlp 0.6.0 depends on numpy\n",
      "    mxnet 1.7.0.post1 depends on numpy<1.17.0 and >=1.8.2\n",
      "    onnxruntime 1.16.0 depends on numpy>=1.24.2\n",
      "    gluonnlp 0.6.0 depends on numpy\n",
      "    mxnet 1.6.0 depends on numpy<1.17.0 and >=1.8.2\n",
      "    onnxruntime 1.16.0 depends on numpy>=1.24.2\n",
      "    gluonnlp 0.6.0 depends on numpy\n",
      "    mxnet 1.5.0 depends on numpy<1.17.0 and >=1.8.2\n",
      "    onnxruntime 1.16.0 depends on numpy>=1.24.2\n",
      "    gluonnlp 0.6.0 depends on numpy\n",
      "    mxnet 1.4.1 depends on numpy<1.17.0 and >=1.8.2\n",
      "    onnxruntime 1.16.0 depends on numpy>=1.24.2\n",
      "    gluonnlp 0.6.0 depends on numpy\n",
      "    mxnet 1.4.0.post0 depends on numpy<1.15.0 and >=1.8.2\n",
      "    onnxruntime 1.16.0 depends on numpy>=1.24.2\n",
      "    gluonnlp 0.6.0 depends on numpy\n",
      "    mxnet 1.4.0 depends on numpy<1.15.0 and >=1.8.2\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet 'https://****@github.com/lifeandmyth/study_KoBERT.git' 'C:\\Users\\hi\\AppData\\Local\\Temp\\pip-req-build-x8whkm49'\n",
      "ERROR: Cannot install kobert because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n"
     ]
    }
   ],
   "source": [
    "# !pip install ipywidgets  # for vscode\n",
    "## !pip install git+https://git@github.com/SKTBrain/KoBERT.git@master => onnxruntime 1.8.0이 배포 버전에 없어서 안됨\n",
    "!pip install git+https://git@github.com/lifeandmyth/study_KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5mTNl7BKT2Fx"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mxnet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmxnet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgluon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmxnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gluon\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmxnet\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmx\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mxnet'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from mxnet.gluon import nn\n",
    "from mxnet import gluon\n",
    "import mxnet as mx\n",
    "import gluonnlp as nlp\n",
    "\n",
    "from kobert import get_mxnet_kobert_model\n",
    "from kobert import get_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cc-zco-ST2F_"
   },
   "source": [
    "### Loading KoBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU\n",
    "ctx = mx.cpu()\n",
    "\n",
    "# GPU\n",
    "# ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "wI841Zb38XOn",
    "outputId": "f9794e99-c913-4ca0-b8fd-6e15ce9d74c7"
   },
   "outputs": [],
   "source": [
    "bert_base, vocab = get_mxnet_kobert_model(use_decoder=False, use_classifier=False, ctx=ctx, cachedir=\".cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "NijpWe8J8isZ",
    "outputId": "d03d1cc1-327f-4b44-ed66-f02126687688"
   },
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93
    },
    "colab_type": "code",
    "id": "i69AUj9gT2Gk",
    "outputId": "050d42de-ac07-4c04-9f14-b5ea411df008"
   },
   "outputs": [],
   "source": [
    "ds = gluon.data.SimpleDataset([['나 보기가 역겨워', '김소월']])\n",
    "trans = nlp.data.BERTSentenceTransform(tok, max_seq_length=10)\n",
    "\n",
    "list(ds.transform(trans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "colab_type": "code",
    "id": "4qy9g_UMVtdj",
    "outputId": "c4546df4-ce5b-4484-e245-309c90fed014"
   },
   "outputs": [],
   "source": [
    "!wget -O .cache/ratings_train.txt http://skt-lsl-nlp-model.s3.amazonaws.com/KoBERT/datasets/nsmc/ratings_train.txt\n",
    "!wget -O .cache/ratings_test.txt http://skt-lsl-nlp-model.s3.amazonaws.com/KoBERT/datasets/nsmc/ratings_test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4LfCTweqT2Gt"
   },
   "outputs": [],
   "source": [
    "dataset_train = nlp.data.TSVDataset(\".cache/ratings_train.txt\", field_indices=[1,2], num_discard_samples=1)\n",
    "dataset_test = nlp.data.TSVDataset(\".cache/ratings_test.txt\", field_indices=[1,2], num_discard_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pt0raV8uT2G2"
   },
   "outputs": [],
   "source": [
    "class BERTDataset(mx.gluon.data.Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "        sent_dataset = gluon.data.SimpleDataset([[\n",
    "            i[sent_idx],\n",
    "        ] for i in dataset])\n",
    "        self.sentences = sent_dataset.transform(transform)\n",
    "        self.labels = gluon.data.SimpleDataset(\n",
    "            [np.array(np.int32(i[label_idx])) for i in dataset])\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vtk-8pQST2G9"
   },
   "outputs": [],
   "source": [
    "max_len = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_K_BLZP_T2HF"
   },
   "outputs": [],
   "source": [
    "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
    "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rhaw0H4ST2HM"
   },
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Block):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 num_classes=2,\n",
    "                 dropout=None,\n",
    "                 prefix=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__(prefix=prefix, params=params)\n",
    "        self.bert = bert\n",
    "        with self.name_scope():\n",
    "            self.classifier = nn.HybridSequential(prefix=prefix)\n",
    "            if dropout:\n",
    "                self.classifier.add(nn.Dropout(rate=dropout))\n",
    "            self.classifier.add(nn.Dense(units=num_classes))\n",
    "\n",
    "    def forward(self, inputs, token_types, valid_length=None):\n",
    "        _, pooler = self.bert(inputs, token_types, valid_length)\n",
    "        return self.classifier(pooler)\n",
    "                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y00BOPwST2HX"
   },
   "outputs": [],
   "source": [
    "model = BERTClassifier(bert_base, num_classes=2, dropout=0.1)\n",
    "# 분류 레이어만 초기화 한다. \n",
    "model.classifier.initialize(init=mx.init.Normal(0.02), ctx=ctx)\n",
    "model.hybridize()\n",
    "\n",
    "# softmax cross entropy loss for classification\n",
    "loss_function = gluon.loss.SoftmaxCELoss()\n",
    "\n",
    "metric = mx.metric.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A2dLhnHkT2Hf"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "lr = 5e-5\n",
    "\n",
    "train_dataloader = mx.gluon.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "test_dataloader = mx.gluon.data.DataLoader(data_test, batch_size=int(batch_size/2), num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ESo76UH-T2Hr"
   },
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(model.collect_params(), 'bertadam',\n",
    "                        {'learning_rate': lr, 'epsilon': 1e-9, 'wd':0.01})\n",
    "\n",
    "log_interval = 4\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wspMBDOAT2H0"
   },
   "outputs": [],
   "source": [
    "# LayerNorm과 Bias에는 Weight Decay를 적용하지 않는다. \n",
    "for _, v in model.collect_params('.*beta|.*gamma|.*bias').items():\n",
    "    v.wd_mult = 0.0\n",
    "params = [\n",
    "    p for p in model.collect_params().values() if p.grad_req != 'null'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NCR6AMKHT2H6"
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(model, data_iter, ctx=ctx):\n",
    "    acc = mx.metric.Accuracy()\n",
    "    i = 0\n",
    "    for i, (t,v,s, label) in enumerate(data_iter):\n",
    "        token_ids = t.as_in_context(ctx)\n",
    "        valid_length = v.as_in_context(ctx)\n",
    "        segment_ids = s.as_in_context(ctx)\n",
    "        label = label.as_in_context(ctx)\n",
    "        output = model(token_ids, segment_ids, valid_length.astype('float32'))\n",
    "        acc.update(preds=output, labels=label)\n",
    "        if i > 1000:\n",
    "            break\n",
    "        i += 1\n",
    "    return(acc.get()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SkcW6GyeT2IA"
   },
   "outputs": [],
   "source": [
    "#learning rate warmup을 위한 준비 \n",
    "accumulate = 4\n",
    "step_size = batch_size * accumulate if accumulate else batch_size\n",
    "num_train_examples = len(data_train)\n",
    "num_train_steps = int(num_train_examples / step_size * num_epochs)\n",
    "warmup_ratio = 0.1\n",
    "num_warmup_steps = int(num_train_steps * warmup_ratio)\n",
    "step_num = 0\n",
    "all_model_params = model.collect_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yf_rpZTq6uES"
   },
   "outputs": [],
   "source": [
    "# Set grad_req if gradient accumulation is required\n",
    "if accumulate and accumulate > 1:\n",
    "    for p in params:\n",
    "        p.grad_req = 'add'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 984
    },
    "colab_type": "code",
    "id": "0mJ3Pw_VT2IH",
    "outputId": "abc9ecfb-8674-445f-cd5d-3fcd57252f39"
   },
   "outputs": [],
   "source": [
    "for epoch_id in range(num_epochs):\n",
    "    metric.reset()\n",
    "    step_loss = 0\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "        if step_num < num_warmup_steps:\n",
    "            new_lr = lr * step_num / num_warmup_steps\n",
    "        else:\n",
    "            non_warmup_steps = step_num - num_warmup_steps\n",
    "            offset = non_warmup_steps / (num_train_steps - num_warmup_steps)\n",
    "            new_lr = lr - offset * lr\n",
    "        trainer.set_learning_rate(new_lr)\n",
    "        with mx.autograd.record():\n",
    "            # load data to GPU\n",
    "            token_ids = token_ids.as_in_context(ctx)\n",
    "            valid_length = valid_length.as_in_context(ctx)\n",
    "            segment_ids = segment_ids.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "\n",
    "            # forward computation\n",
    "            out = model(token_ids, segment_ids, valid_length.astype('float32'))\n",
    "            ls = loss_function(out, label).mean()\n",
    "\n",
    "        # backward computation\n",
    "        ls.backward()\n",
    "        if not accumulate or (batch_id + 1) % accumulate == 0:\n",
    "          trainer.allreduce_grads()\n",
    "          nlp.utils.clip_grad_global_norm(params, 1)\n",
    "          trainer.update(accumulate if accumulate else 1)\n",
    "          step_num += 1\n",
    "          if accumulate and accumulate > 1:\n",
    "              # set grad to zero for gradient accumulation\n",
    "              all_model_params.zero_grad()\n",
    "\n",
    "        step_loss += ls.asscalar()\n",
    "        metric.update([label], [out])\n",
    "        if (batch_id + 1) % (50) == 0:\n",
    "            print('[Epoch {} Batch {}/{}] loss={:.4f}, lr={:.10f}, acc={:.3f}'\n",
    "                         .format(epoch_id + 1, batch_id + 1, len(train_dataloader),\n",
    "                                 step_loss / log_interval,\n",
    "                                 trainer.learning_rate, metric.get()[1]))\n",
    "            step_loss = 0\n",
    "    test_acc = evaluate_accuracy(model, test_dataloader, ctx)\n",
    "    print('Test Acc : {}'.format(test_acc))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "naver_review_classifications_gluon_bert.ipynb의 사본",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "kobert_c_venv",
   "language": "python",
   "name": "kobert_c_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
