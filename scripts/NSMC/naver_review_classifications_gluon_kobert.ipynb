{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KoBERT finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "id": "-sx87sgK7_pz",
    "outputId": "9f1c67bf-7c67-45d7-88b7-4bbc7384a29b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://****@github.com/lifeandmyth/study_KoBERT.git@master\n",
      "  Cloning https://****@github.com/lifeandmyth/study_KoBERT.git (to revision master) to c:\\users\\hi\\appdata\\local\\temp\\pip-req-build-1cbnv1zb\n",
      "  Resolved https://****@github.com/lifeandmyth/study_KoBERT.git to commit e69bdee1462929c6ba1a43c6e370faa282c0395a\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting boto3 (from kobert==0.2.3)\n",
      "  Obtaining dependency information for boto3 from https://files.pythonhosted.org/packages/fe/15/fa88dc3bf239fe047fcd9f7c1c38b655f533d453d4d6c3f72ab5b145d44d/boto3-1.28.53-py3-none-any.whl.metadata\n",
      "  Using cached boto3-1.28.53-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting gluonnlp (from kobert==0.2.3)\n",
      "  Using cached gluonnlp-0.10.0.tar.gz (344 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting mxnet (from kobert==0.2.3)\n",
      "  Using cached mxnet-1.7.0.post2-py2.py3-none-win_amd64.whl (33.1 MB)\n",
      "Collecting onnxruntime (from kobert==0.2.3)\n",
      "  Obtaining dependency information for onnxruntime from https://files.pythonhosted.org/packages/0c/14/9966e648a48f9bfee456002700cde4ca41f1e04ebaea842ccf663b6e7db2/onnxruntime-1.16.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached onnxruntime-1.16.0-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting sentencepiece (from kobert==0.2.3)\n",
      "  Using cached sentencepiece-0.1.99-cp311-cp311-win_amd64.whl (977 kB)\n",
      "Collecting torch (from kobert==0.2.3)\n",
      "  Using cached torch-2.0.1-cp311-cp311-win_amd64.whl (172.3 MB)\n",
      "Collecting transformers (from kobert==0.2.3)\n",
      "  Obtaining dependency information for transformers from https://files.pythonhosted.org/packages/1a/06/3817f9bb923437ead9a794f0ac0d03b8b5e0478ab112db4c413dd37c09da/transformers-4.33.2-py3-none-any.whl.metadata\n",
      "  Using cached transformers-4.33.2-py3-none-any.whl.metadata (119 kB)\n",
      "Collecting botocore<1.32.0,>=1.31.53 (from boto3->kobert==0.2.3)\n",
      "  Obtaining dependency information for botocore<1.32.0,>=1.31.53 from https://files.pythonhosted.org/packages/21/fd/d8591332f5a6b3a94a55dc88a8374518ef7caa24302562558e4eac07ec2e/botocore-1.31.53-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.31.53-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->kobert==0.2.3)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3->kobert==0.2.3)\n",
      "  Obtaining dependency information for s3transfer<0.7.0,>=0.6.0 from https://files.pythonhosted.org/packages/d9/17/a3b666f5ef9543cfd3c661d39d1e193abb9649d0cfbbfee3cf3b51d5af02/s3transfer-0.6.2-py3-none-any.whl.metadata\n",
      "  Using cached s3transfer-0.6.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting numpy>=1.16.0 (from gluonnlp->kobert==0.2.3)\n",
      "  Obtaining dependency information for numpy>=1.16.0 from https://files.pythonhosted.org/packages/93/fd/3f826c6d15d3bdcf65b8031e4835c52b7d9c45add25efa2314b53850e1a2/numpy-1.26.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached numpy-1.26.0-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Collecting cython (from gluonnlp->kobert==0.2.3)\n",
      "  Obtaining dependency information for cython from https://files.pythonhosted.org/packages/ea/8f/216de5d7bede3e26a7131b427a8aadade032f03f9c8ee88792def02e2cf4/Cython-3.0.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached Cython-3.0.2-cp311-cp311-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting packaging (from gluonnlp->kobert==0.2.3)\n",
      "  Using cached packaging-23.1-py3-none-any.whl (48 kB)\n",
      "Collecting numpy>=1.16.0 (from gluonnlp->kobert==0.2.3)\n",
      "  Using cached numpy-1.16.6.zip (5.1 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet 'https://****@github.com/lifeandmyth/study_KoBERT.git' 'C:\\Users\\hi\\AppData\\Local\\Temp\\pip-req-build-1cbnv1zb'\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [260 lines of output]\n",
      "  Running from numpy source directory.\n",
      "  <string>:394: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates\n",
      "  C:\\Users\\hi\\AppData\\Local\\Temp\\pip-install-znw_yll6\\numpy_43b134d6e2404ceb99dcc1ef70c9e5f8\\numpy\\distutils\\misc_util.py:476: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "    return is_string(s) and ('*' in s or '?' is s)\n",
      "  blas_opt_info:\n",
      "  blas_mkl_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries mkl_rt not found in ['C:\\\\playdata_caffeine\\\\KoBERT\\\\kobert_venv\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\hi\\\\anaconda3\\\\Library\\\\lib']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  blis_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries blis not found in ['C:\\\\playdata_caffeine\\\\KoBERT\\\\kobert_venv\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\hi\\\\anaconda3\\\\Library\\\\lib']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  openblas_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries openblas not found in ['C:\\\\playdata_caffeine\\\\KoBERT\\\\kobert_venv\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\hi\\\\anaconda3\\\\Library\\\\lib']\n",
      "  get_default_fcompiler: matching types: '['gnu', 'intelv', 'absoft', 'compaqv', 'intelev', 'gnu95', 'g95', 'intelvem', 'intelem', 'flang']'\n",
      "  customize GnuFCompiler\n",
      "  Could not locate executable g77\n",
      "  Could not locate executable f77\n",
      "  customize IntelVisualFCompiler\n",
      "  Could not locate executable ifort\n",
      "  Could not locate executable ifl\n",
      "  customize AbsoftFCompiler\n",
      "  Could not locate executable f90\n",
      "  customize CompaqVisualFCompiler\n",
      "  Found executable C:\\Users\\hi\\Desktop\\cmder\\vendor\\git-for-windows\\usr\\bin\\DF.exe\n",
      "  customize IntelItaniumVisualFCompiler\n",
      "  Could not locate executable efl\n",
      "  customize Gnu95FCompiler\n",
      "  Could not locate executable gfortran\n",
      "  Could not locate executable f95\n",
      "  customize G95FCompiler\n",
      "  Could not locate executable g95\n",
      "  customize IntelEM64VisualFCompiler\n",
      "  customize IntelEM64TFCompiler\n",
      "  Could not locate executable efort\n",
      "  Could not locate executable efc\n",
      "  customize PGroupFlangCompiler\n",
      "  Could not locate executable flang\n",
      "  don't know how to compile Fortran code on platform 'nt'\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_3_10_blas_threads_info:\n",
      "  Setting PTATLAS=ATLAS\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries tatlas not found in ['C:\\\\playdata_caffeine\\\\KoBERT\\\\kobert_venv\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\hi\\\\anaconda3\\\\Library\\\\lib']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_3_10_blas_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries satlas not found in ['C:\\\\playdata_caffeine\\\\KoBERT\\\\kobert_venv\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\hi\\\\anaconda3\\\\Library\\\\lib']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_blas_threads_info:\n",
      "  Setting PTATLAS=ATLAS\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries ptf77blas,ptcblas,atlas not found in ['C:\\\\playdata_caffeine\\\\KoBERT\\\\kobert_venv\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\hi\\\\anaconda3\\\\Library\\\\lib']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_blas_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries f77blas,cblas,atlas not found in ['C:\\\\playdata_caffeine\\\\KoBERT\\\\kobert_venv\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\hi\\\\anaconda3\\\\Library\\\\lib']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  accelerate_info:\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  C:\\Users\\hi\\AppData\\Local\\Temp\\pip-install-znw_yll6\\numpy_43b134d6e2404ceb99dcc1ef70c9e5f8\\numpy\\distutils\\system_info.py:639: UserWarning:\n",
      "      Atlas (http://math-atlas.sourceforge.net/) libraries not found.\n",
      "      Directories to search for the libraries can be specified in the\n",
      "      numpy/distutils/site.cfg file (section [atlas]) or by setting\n",
      "      the ATLAS environment variable.\n",
      "    self.calc_info()\n",
      "  blas_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries blas not found in ['C:\\\\playdata_caffeine\\\\KoBERT\\\\kobert_venv\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\hi\\\\anaconda3\\\\Library\\\\lib']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  C:\\Users\\hi\\AppData\\Local\\Temp\\pip-install-znw_yll6\\numpy_43b134d6e2404ceb99dcc1ef70c9e5f8\\numpy\\distutils\\system_info.py:639: UserWarning:\n",
      "      Blas (http://www.netlib.org/blas/) libraries not found.\n",
      "      Directories to search for the libraries can be specified in the\n",
      "      numpy/distutils/site.cfg file (section [blas]) or by setting\n",
      "      the BLAS environment variable.\n",
      "    self.calc_info()\n",
      "  blas_src_info:\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  C:\\Users\\hi\\AppData\\Local\\Temp\\pip-install-znw_yll6\\numpy_43b134d6e2404ceb99dcc1ef70c9e5f8\\numpy\\distutils\\system_info.py:639: UserWarning:\n",
      "      Blas (http://www.netlib.org/blas/) sources not found.\n",
      "      Directories to search for the sources can be specified in the\n",
      "      numpy/distutils/site.cfg file (section [blas_src]) or by setting\n",
      "      the BLAS_SRC environment variable.\n",
      "    self.calc_info()\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  'svnversion'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "  배치 파일이 아닙니다.\n",
      "  non-existing path in 'numpy\\\\distutils': 'site.cfg'\n",
      "  lapack_opt_info:\n",
      "  lapack_mkl_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries mkl_rt not found in ['C:\\\\playdata_caffeine\\\\KoBERT\\\\kobert_venv\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\hi\\\\anaconda3\\\\Library\\\\lib']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  openblas_lapack_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries openblas not found in ['C:\\\\playdata_caffeine\\\\KoBERT\\\\kobert_venv\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\hi\\\\anaconda3\\\\Library\\\\lib']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  openblas_clapack_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries openblas,lapack not found in ['C:\\\\playdata_caffeine\\\\KoBERT\\\\kobert_venv\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\hi\\\\anaconda3\\\\Library\\\\lib']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_3_10_threads_info:\n",
      "  Setting PTATLAS=ATLAS\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\playdata_caffeine\\KoBERT\\kobert_venv\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries tatlas,tatlas not found in C:\\playdata_caffeine\\KoBERT\\kobert_venv\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries tatlas,tatlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\Users\\hi\\anaconda3\\Library\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries tatlas,tatlas not found in C:\\Users\\hi\\anaconda3\\Library\\lib\n",
      "  <class 'numpy.distutils.system_info.atlas_3_10_threads_info'>\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_3_10_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\playdata_caffeine\\KoBERT\\kobert_venv\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries satlas,satlas not found in C:\\playdata_caffeine\\KoBERT\\kobert_venv\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries satlas,satlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\Users\\hi\\anaconda3\\Library\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries satlas,satlas not found in C:\\Users\\hi\\anaconda3\\Library\\lib\n",
      "  <class 'numpy.distutils.system_info.atlas_3_10_info'>\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_threads_info:\n",
      "  Setting PTATLAS=ATLAS\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\playdata_caffeine\\KoBERT\\kobert_venv\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries ptf77blas,ptcblas,atlas not found in C:\\playdata_caffeine\\KoBERT\\kobert_venv\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries ptf77blas,ptcblas,atlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\Users\\hi\\anaconda3\\Library\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries ptf77blas,ptcblas,atlas not found in C:\\Users\\hi\\anaconda3\\Library\\lib\n",
      "  <class 'numpy.distutils.system_info.atlas_threads_info'>\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\playdata_caffeine\\KoBERT\\kobert_venv\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries f77blas,cblas,atlas not found in C:\\playdata_caffeine\\KoBERT\\kobert_venv\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries f77blas,cblas,atlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\Users\\hi\\anaconda3\\Library\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries f77blas,cblas,atlas not found in C:\\Users\\hi\\anaconda3\\Library\\lib\n",
      "  <class 'numpy.distutils.system_info.atlas_info'>\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  lapack_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack not found in ['C:\\\\playdata_caffeine\\\\KoBERT\\\\kobert_venv\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\hi\\\\anaconda3\\\\Library\\\\lib']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  C:\\Users\\hi\\AppData\\Local\\Temp\\pip-install-znw_yll6\\numpy_43b134d6e2404ceb99dcc1ef70c9e5f8\\numpy\\distutils\\system_info.py:639: UserWarning:\n",
      "      Lapack (http://www.netlib.org/lapack/) libraries not found.\n",
      "      Directories to search for the libraries can be specified in the\n",
      "      numpy/distutils/site.cfg file (section [lapack]) or by setting\n",
      "      the LAPACK environment variable.\n",
      "    self.calc_info()\n",
      "  lapack_src_info:\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  C:\\Users\\hi\\AppData\\Local\\Temp\\pip-install-znw_yll6\\numpy_43b134d6e2404ceb99dcc1ef70c9e5f8\\numpy\\distutils\\system_info.py:639: UserWarning:\n",
      "      Lapack (http://www.netlib.org/lapack/) sources not found.\n",
      "      Directories to search for the sources can be specified in the\n",
      "      numpy/distutils/site.cfg file (section [lapack_src]) or by setting\n",
      "      the LAPACK_SRC environment variable.\n",
      "    self.calc_info()\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  C:\\Users\\hi\\AppData\\Local\\Temp\\pip-build-env-rx0k17zs\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py:265: UserWarning: Unknown distribution option: 'define_macros'\n",
      "    warnings.warn(msg)\n",
      "  running dist_info\n",
      "  running build_src\n",
      "  build_src\n",
      "  building py_modules sources\n",
      "  creating build\n",
      "  creating build\\src.win-amd64-3.1\n",
      "  creating build\\src.win-amd64-3.1\\numpy\n",
      "  creating build\\src.win-amd64-3.1\\numpy\\distutils\n",
      "  building library \"npymath\" sources\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "## !pip install ipywidgets # for vscode\n",
    "## !pip install git+https://git@github.com/SKTBrain/KoBERT.git@master => onnxruntime 1.8.0이 배포 버전에 없어서 안됨\n",
    "!pip install git+https://git@github.com/lifeandmyth/study_KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5mTNl7BKT2Fx"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mxnet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmxnet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgluon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmxnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gluon\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmxnet\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmx\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mxnet'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from mxnet.gluon import nn\n",
    "from mxnet import gluon\n",
    "import mxnet as mx\n",
    "import gluonnlp as nlp\n",
    "\n",
    "from kobert import get_mxnet_kobert_model\n",
    "from kobert import get_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cc-zco-ST2F_"
   },
   "source": [
    "### Loading KoBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU\n",
    "ctx = mx.cpu()\n",
    "\n",
    "# GPU\n",
    "# ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "wI841Zb38XOn",
    "outputId": "f9794e99-c913-4ca0-b8fd-6e15ce9d74c7"
   },
   "outputs": [],
   "source": [
    "bert_base, vocab = get_mxnet_kobert_model(use_decoder=False, use_classifier=False, ctx=ctx, cachedir=\".cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "NijpWe8J8isZ",
    "outputId": "d03d1cc1-327f-4b44-ed66-f02126687688"
   },
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93
    },
    "colab_type": "code",
    "id": "i69AUj9gT2Gk",
    "outputId": "050d42de-ac07-4c04-9f14-b5ea411df008"
   },
   "outputs": [],
   "source": [
    "ds = gluon.data.SimpleDataset([['나 보기가 역겨워', '김소월']])\n",
    "trans = nlp.data.BERTSentenceTransform(tok, max_seq_length=10)\n",
    "\n",
    "list(ds.transform(trans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "colab_type": "code",
    "id": "4qy9g_UMVtdj",
    "outputId": "c4546df4-ce5b-4484-e245-309c90fed014"
   },
   "outputs": [],
   "source": [
    "!wget -O .cache/ratings_train.txt http://skt-lsl-nlp-model.s3.amazonaws.com/KoBERT/datasets/nsmc/ratings_train.txt\n",
    "!wget -O .cache/ratings_test.txt http://skt-lsl-nlp-model.s3.amazonaws.com/KoBERT/datasets/nsmc/ratings_test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4LfCTweqT2Gt"
   },
   "outputs": [],
   "source": [
    "dataset_train = nlp.data.TSVDataset(\".cache/ratings_train.txt\", field_indices=[1,2], num_discard_samples=1)\n",
    "dataset_test = nlp.data.TSVDataset(\".cache/ratings_test.txt\", field_indices=[1,2], num_discard_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pt0raV8uT2G2"
   },
   "outputs": [],
   "source": [
    "class BERTDataset(mx.gluon.data.Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "        sent_dataset = gluon.data.SimpleDataset([[\n",
    "            i[sent_idx],\n",
    "        ] for i in dataset])\n",
    "        self.sentences = sent_dataset.transform(transform)\n",
    "        self.labels = gluon.data.SimpleDataset(\n",
    "            [np.array(np.int32(i[label_idx])) for i in dataset])\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vtk-8pQST2G9"
   },
   "outputs": [],
   "source": [
    "max_len = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_K_BLZP_T2HF"
   },
   "outputs": [],
   "source": [
    "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
    "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rhaw0H4ST2HM"
   },
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Block):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 num_classes=2,\n",
    "                 dropout=None,\n",
    "                 prefix=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__(prefix=prefix, params=params)\n",
    "        self.bert = bert\n",
    "        with self.name_scope():\n",
    "            self.classifier = nn.HybridSequential(prefix=prefix)\n",
    "            if dropout:\n",
    "                self.classifier.add(nn.Dropout(rate=dropout))\n",
    "            self.classifier.add(nn.Dense(units=num_classes))\n",
    "\n",
    "    def forward(self, inputs, token_types, valid_length=None):\n",
    "        _, pooler = self.bert(inputs, token_types, valid_length)\n",
    "        return self.classifier(pooler)\n",
    "                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y00BOPwST2HX"
   },
   "outputs": [],
   "source": [
    "model = BERTClassifier(bert_base, num_classes=2, dropout=0.1)\n",
    "# 분류 레이어만 초기화 한다. \n",
    "model.classifier.initialize(init=mx.init.Normal(0.02), ctx=ctx)\n",
    "model.hybridize()\n",
    "\n",
    "# softmax cross entropy loss for classification\n",
    "loss_function = gluon.loss.SoftmaxCELoss()\n",
    "\n",
    "metric = mx.metric.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A2dLhnHkT2Hf"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "lr = 5e-5\n",
    "\n",
    "train_dataloader = mx.gluon.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "test_dataloader = mx.gluon.data.DataLoader(data_test, batch_size=int(batch_size/2), num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ESo76UH-T2Hr"
   },
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(model.collect_params(), 'bertadam',\n",
    "                        {'learning_rate': lr, 'epsilon': 1e-9, 'wd':0.01})\n",
    "\n",
    "log_interval = 4\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wspMBDOAT2H0"
   },
   "outputs": [],
   "source": [
    "# LayerNorm과 Bias에는 Weight Decay를 적용하지 않는다. \n",
    "for _, v in model.collect_params('.*beta|.*gamma|.*bias').items():\n",
    "    v.wd_mult = 0.0\n",
    "params = [\n",
    "    p for p in model.collect_params().values() if p.grad_req != 'null'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NCR6AMKHT2H6"
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(model, data_iter, ctx=ctx):\n",
    "    acc = mx.metric.Accuracy()\n",
    "    i = 0\n",
    "    for i, (t,v,s, label) in enumerate(data_iter):\n",
    "        token_ids = t.as_in_context(ctx)\n",
    "        valid_length = v.as_in_context(ctx)\n",
    "        segment_ids = s.as_in_context(ctx)\n",
    "        label = label.as_in_context(ctx)\n",
    "        output = model(token_ids, segment_ids, valid_length.astype('float32'))\n",
    "        acc.update(preds=output, labels=label)\n",
    "        if i > 1000:\n",
    "            break\n",
    "        i += 1\n",
    "    return(acc.get()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SkcW6GyeT2IA"
   },
   "outputs": [],
   "source": [
    "#learning rate warmup을 위한 준비 \n",
    "accumulate = 4\n",
    "step_size = batch_size * accumulate if accumulate else batch_size\n",
    "num_train_examples = len(data_train)\n",
    "num_train_steps = int(num_train_examples / step_size * num_epochs)\n",
    "warmup_ratio = 0.1\n",
    "num_warmup_steps = int(num_train_steps * warmup_ratio)\n",
    "step_num = 0\n",
    "all_model_params = model.collect_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yf_rpZTq6uES"
   },
   "outputs": [],
   "source": [
    "# Set grad_req if gradient accumulation is required\n",
    "if accumulate and accumulate > 1:\n",
    "    for p in params:\n",
    "        p.grad_req = 'add'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 984
    },
    "colab_type": "code",
    "id": "0mJ3Pw_VT2IH",
    "outputId": "abc9ecfb-8674-445f-cd5d-3fcd57252f39"
   },
   "outputs": [],
   "source": [
    "for epoch_id in range(num_epochs):\n",
    "    metric.reset()\n",
    "    step_loss = 0\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "        if step_num < num_warmup_steps:\n",
    "            new_lr = lr * step_num / num_warmup_steps\n",
    "        else:\n",
    "            non_warmup_steps = step_num - num_warmup_steps\n",
    "            offset = non_warmup_steps / (num_train_steps - num_warmup_steps)\n",
    "            new_lr = lr - offset * lr\n",
    "        trainer.set_learning_rate(new_lr)\n",
    "        with mx.autograd.record():\n",
    "            # load data to GPU\n",
    "            token_ids = token_ids.as_in_context(ctx)\n",
    "            valid_length = valid_length.as_in_context(ctx)\n",
    "            segment_ids = segment_ids.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "\n",
    "            # forward computation\n",
    "            out = model(token_ids, segment_ids, valid_length.astype('float32'))\n",
    "            ls = loss_function(out, label).mean()\n",
    "\n",
    "        # backward computation\n",
    "        ls.backward()\n",
    "        if not accumulate or (batch_id + 1) % accumulate == 0:\n",
    "          trainer.allreduce_grads()\n",
    "          nlp.utils.clip_grad_global_norm(params, 1)\n",
    "          trainer.update(accumulate if accumulate else 1)\n",
    "          step_num += 1\n",
    "          if accumulate and accumulate > 1:\n",
    "              # set grad to zero for gradient accumulation\n",
    "              all_model_params.zero_grad()\n",
    "\n",
    "        step_loss += ls.asscalar()\n",
    "        metric.update([label], [out])\n",
    "        if (batch_id + 1) % (50) == 0:\n",
    "            print('[Epoch {} Batch {}/{}] loss={:.4f}, lr={:.10f}, acc={:.3f}'\n",
    "                         .format(epoch_id + 1, batch_id + 1, len(train_dataloader),\n",
    "                                 step_loss / log_interval,\n",
    "                                 trainer.learning_rate, metric.get()[1]))\n",
    "            step_loss = 0\n",
    "    test_acc = evaluate_accuracy(model, test_dataloader, ctx)\n",
    "    print('Test Acc : {}'.format(test_acc))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "naver_review_classifications_gluon_bert.ipynb의 사본",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "kobert_c_venv",
   "language": "python",
   "name": "kobert_c_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
